{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "<ul>\n",
    "    <li>Usar o libreoffice e encontrar 2000 palavras erradas (80h)</li>\n",
    "    <li>Classificar as palavras por tipo (80h)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Italian Pipeline</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hunspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3197de6e9e4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msuggestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "suggestions = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'suggestions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7a2a15a51e12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msuggestions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'suggestions' is not defined"
     ]
    }
   ],
   "source": [
    "suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'suggestions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fd000088e8ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msuggestions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'suggestions.auto.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'suggestions' is not defined"
     ]
    }
   ],
   "source": [
    "suggestions.to_csv('suggestions.auto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hunspell\n",
    "it_spellchecker = hunspell.HunSpell('/home/rgomes/dictionaries/dictionaries/it/index.dic', '/home/rgomes/dictionaries/dictionaries/it/index.aff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../auto.spellchecker.results.filtered.json', encoding='utf-8') as data_file:\n",
    "    data = json.loads(data_file.read())\n",
    "    data = list(filter(lambda x: x,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = map(lambda x: x['word'], data)\n",
    "b = map(lambda x : (x,it_spellchecker.spell(x)), a)\n",
    "asd = filter(lambda x: x[1] ,b)\n",
    "errors_hunspell = list(filter(lambda x: x[1] == False , b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_errors = filter(lambda x: re.search(r'[À-ž\\'\\`]', x[0]) ,errors_hunspell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in list(ac_errors):\n",
    "    #print(item[0] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_ac_errors = []\n",
    "with open('../italian_accented_erros.txt', encoding='utf-8') as data_file2:\n",
    "    lines = data_file2.readlines()\n",
    "    corrected_ac_errors = list(filter(lambda y: y != '',map(lambda x: x.rstrip('\\n'), lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_words = []\n",
    "for index,x in enumerate(ac_errors):\n",
    "    if x[0] != corrected_ac_errors[index]:\n",
    "        corrected_words.append((x[0], corrected_ac_errors[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "with open('../italian_words_all.txt', encoding='utf-8') as data_file_all:\n",
    "    lines = data_file_all.readlines()\n",
    "    all_words = list(map(lambda x: x.rstrip('\\n').lower(), lines))\n",
    "    all_words = list(map(lambda x: x.replace('!#$%&()*+,./:;<=>?@[\\\\]_{|}', ''), all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(list):\n",
    "    d={}\n",
    "    for i in list:\n",
    "        if i in d:\n",
    "            d[i] += 1\n",
    "        else:\n",
    "            d[i] = 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistogram(data):\n",
    "    h = histogram(data)\n",
    "    h = sorted(h.items(), key=lambda x: x[1], reverse=True)\n",
    "    h = map(lambda x: x[1], h)\n",
    "    # remove the words that appears only once\n",
    "    h = filter(lambda x: x > 1, h)\n",
    "\n",
    "    plt.plot(list(h))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions_csv = pd.read_csv('/home/rgomes/Downloads/suggestions filtered - suggestions.auto.csv')\n",
    "suggestions_csv = suggestions_csv.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions_csv.drop(['is_italian_word', 'suggestions', 'HELPFUL LINK', 'Already removed words'], axis=1)\n",
    "\n",
    "suggestions_corrected = []\n",
    "for _, row in suggestions_csv.iterrows():\n",
    "    if row['spelling_correction']:\n",
    "        suggestions_corrected.append((row['word'], row['spelling_correction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Aapettiamo', 'Aspettiamo'),\n",
       " ('abiamo', 'abbiamo'),\n",
       " ('Accando', 'accanto'),\n",
       " ('accettavan', 'accetavano'),\n",
       " ('acchitto', 'acchito'),\n",
       " ('accippicchia', 'accipicchia'),\n",
       " ('accomapagnava', 'accompagnava'),\n",
       " ('accompegnerà', 'accompagnera'),\n",
       " ('accozzzaglia', 'accozzaglia'),\n",
       " ('acompagnarmi', 'accompagnarmi'),\n",
       " ('acqistata', 'acquistata'),\n",
       " ('acquiastare', 'acquistare'),\n",
       " ('acquistatato', 'acquistato'),\n",
       " ('adattore', 'adattatore'),\n",
       " ('addocchiato', 'adocchiato'),\n",
       " ('adoloscenti', 'adolescenti'),\n",
       " ('Adoroviaggiare', 'Adoro viaggiare'),\n",
       " ('adosso', 'addosso'),\n",
       " ('aereomobili', 'aeromobili'),\n",
       " ('aereoplano', 'aeroplano'),\n",
       " ('aereoporto', 'aeroporto'),\n",
       " ('Aereoporto', 'aeroporto'),\n",
       " ('aeroportp', 'aeroporto'),\n",
       " ('afffluenza', 'affluenza'),\n",
       " ('affittamotorini', 'affitta motorini'),\n",
       " ('affittao', 'affitto'),\n",
       " ('affollatisssssime', 'affollatissime'),\n",
       " ('Aft', 'afta'),\n",
       " ('agoasto', 'agosto'),\n",
       " ('AgostoIl', 'agosto il'),\n",
       " ('agostoPartiamo', 'agosto Partiamo'),\n",
       " ('agostoSì', 'agosto si'),\n",
       " ('ahime', 'ahimè'),\n",
       " ('aihmè', 'ahimè'),\n",
       " ('aimè', 'ahimè'),\n",
       " ('aiut', 'aiutò'),\n",
       " ('AIUTOOOO', 'aiutò'),\n",
       " ('Aiutoooo', 'aiutò'),\n",
       " ('Aiutoooograzie', 'Aiuto grazie'),\n",
       " ('akmeno', 'almeno'),\n",
       " ('Akmeno', 'almeno'),\n",
       " ('alcunii', 'alcuni'),\n",
       " (\"all'acquawordl\", \"all'acquaworld\"),\n",
       " (\"All'aereoporto\", \"All'aeroporto\"),\n",
       " (\"all'aereoporto\", \"All'aeroporto\"),\n",
       " (\"all'Aereoporto\", \"All'aeroporto\"),\n",
       " (\"all'Alambra\", \"all'Alhambra\"),\n",
       " (\"all'apertocon\", \"all'aperto con\"),\n",
       " (\"all'appestamento\", \"all'appartamento\"),\n",
       " (\"all'appuntamente\", \"all'appuntamento\"),\n",
       " (\"all'Areopoago\", \"all'Areopago\"),\n",
       " (\"all'aroporto\", \"all'aeroporto\"),\n",
       " (\"all'AvanaDunque\", \"all'Avana Dunque\"),\n",
       " (\"all'EasyHotel\", \"all'Easy Hotel\"),\n",
       " (\"All'eroporto\", \"All'aeroporto\"),\n",
       " (\"all'inetrno\", \"all'interno\"),\n",
       " (\"all'Operà\", \"all'Opera\"),\n",
       " (\"all'Operett\", \"all'Operetta\"),\n",
       " ('Allakulikhan', 'Allakuli khan'),\n",
       " ('allametro', 'alla metro'),\n",
       " ('allimacbergamo', 'allimac bergamo'),\n",
       " ('allinterno', \"all'interno\"),\n",
       " ('Almuneda', 'Almudena'),\n",
       " ('altrakasa', \"L' Altra Kasa\"),\n",
       " ('altrimetni', 'altrimenti'),\n",
       " ('alzatina', 'alzatine'),\n",
       " ('amburgoho', 'amburgo'),\n",
       " ('Amgetorv', 'Amgertorv'),\n",
       " ('ammirara', 'ammirare'),\n",
       " ('amplare', 'ampliare'),\n",
       " ('amtrimonio', 'matrimonio'),\n",
       " ('ancche', 'anchè'),\n",
       " ('anddati', 'andati'),\n",
       " ('andimo', 'andiamo'),\n",
       " ('andrichiara', 'andrea chiara'),\n",
       " ('ansisssiiiima', 'ansissima'),\n",
       " ('antibotico', 'antibiotico'),\n",
       " ('anticipitamente', 'anticipatamente'),\n",
       " ('anzichè', 'anziché'),\n",
       " ('appararentemente', 'apparentemente'),\n",
       " ('apperzzare', 'apprezzare'),\n",
       " ('approffitati', 'approfittati'),\n",
       " ('approffittato', 'approfittato'),\n",
       " ('Apranzo', 'A pranzo'),\n",
       " ('aprofittiamo', 'approfittiamo'),\n",
       " ('aquisti', 'acquisti'),\n",
       " ('archelogiche', 'archeologiche'),\n",
       " ('archeoculturale', 'archeo culturale'),\n",
       " ('Archeveché', 'Archevêché'),\n",
       " ('architettonco', 'architettònico'),\n",
       " ('arraffazzonate', 'a rraffazzonate'),\n",
       " ('arrieccomiiiii', 'arrieccomi'),\n",
       " ('arrivanop', 'arrivamo'),\n",
       " ('arrivermo', 'arriveremo'),\n",
       " ('Arriviamoi', 'Arriviamo'),\n",
       " ('arriviamoin', 'arriviamo in'),\n",
       " ('Arrivooo', 'Arrivo'),\n",
       " ('arrresi', 'arresi'),\n",
       " ('Arrviamo', 'Arriviamo'),\n",
       " ('asciugamamani', 'asciugamani'),\n",
       " ('ascoltarloi', 'ascoltarlo'),\n",
       " ('assitenza', 'assistenza'),\n",
       " ('asssoluto', 'assoluto'),\n",
       " ('attaversando', 'attraversando'),\n",
       " ('attaversano', 'attraversando'),\n",
       " ('attaversare', 'attraversare'),\n",
       " ('attivita', 'attività'),\n",
       " ('autodisorganizzato', 'auto disorganizzato'),\n",
       " ('autorganizzato', 'auto organizzato'),\n",
       " ('avevao', 'avevano'),\n",
       " ('avezze', 'avvezze'),\n",
       " ('avra', 'avrà'),\n",
       " ('avutouna', 'avuto una'),\n",
       " ('avvenieristici', 'avveniristici'),\n",
       " ('avvicianiamo', 'avviciniamo'),\n",
       " ('avvicinamentoQualche', 'avvicinamento Qualche'),\n",
       " ('azzeccosi', 'azzeccasi'),\n",
       " ('barcchetta', 'barchetta'),\n",
       " ('BarcellonaIntorno', 'Barcellona Intorno'),\n",
       " ('Barcellonette', 'Barcelonnette'),\n",
       " ('Barcelonette', 'Barcelonnette'),\n",
       " ('Barcolana', 'Barcelona'),\n",
       " ('Barguete', 'Burguete'),\n",
       " ('BARIavendola', 'BARI avendola'),\n",
       " ('Basìlica', 'Basilica'),\n",
       " ('BatalhaCascais', 'Batalha Cascais'),\n",
       " ('Batlò', 'Batllò'),\n",
       " ('Batthiany', 'Batthyány'),\n",
       " ('Batthyàny', 'Batthyány'),\n",
       " ('Battlò', 'Batllò'),\n",
       " ('Batttttttttttttttt', '?'),\n",
       " ('bayernticket', 'bayern ticket'),\n",
       " ('beauvais-parigiA', 'beauvais parigia'),\n",
       " ('Beghjnhoff', 'Begijnhof'),\n",
       " ('Begijnhoff', 'Begijnhof'),\n",
       " ('bellodimamma', 'bello di mamma'),\n",
       " ('belloooooooooo', 'bello'),\n",
       " ('belloooooooooooooooooooo', 'bello'),\n",
       " ('benchè', 'benché'),\n",
       " ('benearrivata', 'ben arrivata'),\n",
       " ('benearrivato', 'ben arrivato'),\n",
       " ('benissmo', 'benissimo')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggestions_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    }
   ],
   "source": [
    "print(len(suggestions_corrected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corrections 252\n",
      "('perchè', 1237)\n",
      "1981\n"
     ]
    }
   ],
   "source": [
    "h = histogram(all_words)\n",
    "h = sorted(h.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#######\n",
    "# filtra apenas aquelas corrigidas com repeticao\n",
    "combined_corrections_map = list(set(corrected_words + suggestions_corrected))\n",
    "print('Total corrections {}'.format(len(combined_corrections_map)))\n",
    "\n",
    "combined_words_list = list(map(lambda x : x[0].lower(), combined_corrections_map))\n",
    "#print(combined_words_list)\n",
    "mapped_combined_words = filter(lambda x : x[0].lower() in combined_words_list, h)\n",
    "\n",
    "total_words = list(mapped_combined_words)\n",
    "print(total_words[0])\n",
    "\n",
    "count = 0\n",
    "for w in total_words:\n",
    "    count = count + w[1]\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 142\n"
     ]
    }
   ],
   "source": [
    "combined_corrections_map\n",
    "print(len(corrected_words), len(suggestions_corrected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21459\n"
     ]
    }
   ],
   "source": [
    "a_ordered = filter(lambda x: re.search(r'[À-ž\\'\\`]', x[0]),h)\n",
    "b_ordered = filter(lambda x: not it_spellchecker.spell(x[0]),a_ordered)\n",
    "c_ordered = filter(lambda x: not(x[0] in combined_words_list),b_ordered)\n",
    "d = list(c_ordered)\n",
    "count2 = 0\n",
    "for w in d:\n",
    "    count2 = count2 + w[1]\n",
    "print(count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../ordered_last_errors.txt', 'w') as ordered_last_errors:\n",
    "    for item in d:\n",
    "        ordered_last_errors.write(item[0] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "last_corrections = []\n",
    "with open('../ordered_last_errors_corrected.txt') as ordered_last_corrections:\n",
    "    lines = list(map(lambda x: x.rstrip('\\n').lower(), ordered_last_corrections))\n",
    "    for index, item in enumerate(d):\n",
    "        if item[0] != lines[index]:\n",
    "            last_corrections.append((item[0],lines[index]))\n",
    "print(len(last_corrections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corrections 344\n",
      "('perchè', 1237)\n",
      "4537\n"
     ]
    }
   ],
   "source": [
    "h = histogram(all_words)\n",
    "h = sorted(h.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# filtra apenas aquelas corrigidas com repeticao\n",
    "combined_corrections_map = list(set(corrected_words + suggestions_corrected + last_corrections))\n",
    "#combined_corrections_map = list(map(lambda x : (x[0].replace('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~', ''), combined_corrections_map)))\n",
    "print('Total corrections {}'.format(len(combined_corrections_map)))\n",
    "\n",
    "combined_words_list = list(map(lambda x : x[0].lower(), combined_corrections_map))\n",
    "#print(combined_words_list)\n",
    "mapped_combined_words = list(filter(lambda x : x[0].lower() in combined_words_list, h))\n",
    "\n",
    "#remove rare cases and outliers\n",
    "# todo: remove nonsense words verified by norton\n",
    "total_words = list(filter(lambda x: x[1] > 1 and x[1] < 2200,mapped_combined_words))\n",
    "\n",
    "print(total_words[0])\n",
    "\n",
    "count = 0\n",
    "for w in total_words:\n",
    "    count = count + w[1]\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_count_dict = dict((a[0], a) for a in total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corrections_dict = dict((a[0], a) for a in combined_corrections_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for item in all_count_dict:\n",
    "    if all_corrections_dict.get(item):\n",
    "        all_data.append((item, all_count_dict[item][1], all_corrections_dict[item][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-032d706702ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(all_data))\n",
    "df = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../final_corrections.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
